# üé§ –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞: –ì–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è

## –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### 1. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (STT)

```typescript
// src/services/yandex-stt.service.ts

import { createLogger } from "../utils/logger.js";

const logger = createLogger("YandexSTT");

export interface YandexSTTRequest {
  apiKey: string;
  folderId: string;
  audioBuffer: Buffer;
  languageCode?: string;
}

/**
 * –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Yandex SpeechKit
 */
export async function recognizeSpeech(
  request: YandexSTTRequest
): Promise<string> {
  const { apiKey, folderId, audioBuffer, languageCode = "ru-RU" } = request;

  logger.info(`Recognizing speech (size: ${audioBuffer.length} bytes)...`);

  const response = await fetch(
    "https://stt.api.cloud.yandex.net/speech/v1/stt:recognize",
    {
      method: "POST",
      headers: {
        Authorization: `Api-Key ${apiKey}`,
        "x-folder-id": folderId,
      },
      body: audioBuffer,
    }
  );

  if (!response.ok) {
    throw new Error(`Yandex STT API error: ${response.status}`);
  }

  const data = await response.json();
  const text = data.result?.alternatives?.[0]?.text || "";

  logger.info(`Speech recognized: ${text}`);
  return text;
}
```

### 2. –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

```typescript
// src/handlers/voice.handler.ts

import { BotContext } from "../types/index.js";
import { recognizeSpeech } from "../services/yandex-stt.service.js";
import { generateIdea } from "../lib/ai.js";

/**
 * –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
 */
export async function voiceHandler(ctx: BotContext): Promise<void> {
  // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
  if (!ctx.message || !("voice" in ctx.message)) {
    return;
  }

  const voice = ctx.message.voice;

  // –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (30 —Å–µ–∫ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ API)
  if (voice.duration > 30) {
    await ctx.reply("‚è± –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ (–º–∞–∫—Å. 30 —Å–µ–∫).");
    return;
  }

  try {
    // –®–∞–≥ 1: –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ
    await ctx.reply("üé§ –°–ª—É—à–∞—é –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...");

    const fileLink = await ctx.telegram.getFileLink(voice.file_id);
    const audioResponse = await fetch(fileLink.href);
    const audioBuffer = Buffer.from(await audioResponse.arrayBuffer());

    // –®–∞–≥ 2: –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ä–µ—á—å
    await ctx.reply("üîç –†–∞—Å–ø–æ–∑–Ω–∞—é –≤–∞—à—É —Ä–µ—á—å...");

    const recognizedText = await recognizeSpeech({
      apiKey: config.aiToken!,
      folderId: config.yandexFolderId!,
      audioBuffer,
      languageCode: "ru-RU",
    });

    await ctx.reply(`üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: "${recognizedText}"`);

    // –®–∞–≥ 3: –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–º—É
    const topic = extractTopicFromText(recognizedText);

    // –®–∞–≥ 4: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–¥–µ—é
    await ctx.reply("üí° –ì–µ–Ω–µ—Ä–∏—Ä—É—é –±–∏–∑–Ω–µ—Å-–∏–¥–µ—é...");
    const idea = await generateIdea(topic);

    await ctx.reply(
      `üéØ –ë–∏–∑–Ω–µ—Å-–∏–¥–µ—è –ø–æ —Ç–µ–º–µ "${topic}":\n\n${idea}\n\n` +
        `üé§ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –Ω–æ–≤–æ–π –∏–¥–µ–∏!`
    );
  } catch (error) {
    logger.error("Error processing voice", error);
    await ctx.reply("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.");
  }
}
```

### 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞

```typescript
/**
 * –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–º—É –∏–∑ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
 */
function extractTopicFromText(text: string): string {
  const lowerText = text.toLowerCase();

  // –°–ª–æ–≤–∞—Ä—å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
  const topicKeywords: Record<string, string[]> = {
    sales: ["–ø—Ä–æ–¥–∞–∂–∏", "–ø—Ä–æ–¥–∞–∂", "—Å–µ–π–ª–∑", "–∫–ª–∏–µ–Ω—Ç"],
    marketing: ["–º–∞—Ä–∫–µ—Ç–∏–Ω–≥", "—Ä–µ–∫–ª–∞–º", "smm", "–∫–æ–Ω—Ç–µ–Ω—Ç"],
    hr: ["hr", "–ø–µ—Ä—Å–æ–Ω–∞–ª", "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫", "–Ω–∞–π–º"],
    product: ["–ø—Ä–æ–¥—É–∫—Ç", "—Ä–∞–∑—Ä–∞–±–æ—Ç–∫", "—Ñ–∏—á–∞"],
    support: ["–ø–æ–¥–¥–µ—Ä–∂–∫", "support", "–ø–æ–º–æ—â—å"],
    finance: ["—Ñ–∏–Ω–∞–Ω—Å", "–±—É—Ö–≥–∞–ª—Ç–µ—Ä", "—É—á–µ—Ç"],
  };

  // –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
  for (const [topic, keywords] of Object.entries(topicKeywords)) {
    for (const keyword of keywords) {
      if (lowerText.includes(keyword)) {
        return topic;
      }
    }
  }

  // –î–µ—Ñ–æ–ª—Ç–Ω–∞—è —Ç–µ–º–∞
  return "sales";
}
```

### 4. –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞

```typescript
// api/webhook.ts

import { voiceHandler } from "../src/handlers/index.js";

// ...

// –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
bot.on("voice", voiceHandler);
```

## –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã

### Text-to-Speech (–≥–æ–ª–æ—Å–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã)

```typescript
// src/services/yandex-tts.service.ts

export interface YandexTTSRequest {
  apiKey: string;
  folderId: string;
  text: string;
  voice?: string;
  languageCode?: string;
}

/**
 * –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Yandex SpeechKit
 */
export async function synthesizeSpeech(
  request: YandexTTSRequest
): Promise<Buffer> {
  const {
    apiKey,
    folderId,
    text,
    voice = "alena", // –∏–ª–∏ "filipp", "ermil", "jane", etc.
    languageCode = "ru-RU",
  } = request;

  const response = await fetch(
    "https://tts.api.cloud.yandex.net/speech/v1/tts:synthesize",
    {
      method: "POST",
      headers: {
        Authorization: `Api-Key ${apiKey}`,
        "x-folder-id": folderId,
      },
      body: new URLSearchParams({
        text,
        lang: languageCode,
        voice,
        format: "oggopus", // –§–æ—Ä–º–∞—Ç –¥–ª—è Telegram
        speed: "1.0",
        emotion: "neutral",
      }),
    }
  );

  if (!response.ok) {
    throw new Error(`Yandex TTS API error: ${response.status}`);
  }

  return Buffer.from(await response.arrayBuffer());
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ handler
export async function voiceHandlerWithTTS(ctx: BotContext): Promise<void> {
  // ... —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–¥–µ–∏ ...

  // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
  await ctx.reply(`üìù ${idea}`);

  // –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç
  const audioBuffer = await synthesizeSpeech({
    apiKey: config.aiToken!,
    folderId: config.yandexFolderId!,
    text: idea,
    voice: "alena",
  });

  // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
  await ctx.replyWithVoice({ source: audioBuffer });
}
```

### –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ

```typescript
/**
 * –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
 */
async function recognizeSpeechWithLangDetection(
  audioBuffer: Buffer,
  apiKey: string,
  folderId: string
): Promise<{ text: string; language: string }> {
  // –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —è–∑—ã–∫–æ–≤
  const languages = ["ru-RU", "en-US", "de-DE"];

  let bestResult = { text: "", confidence: 0, language: "ru-RU" };

  for (const lang of languages) {
    try {
      const response = await fetch(
        `https://stt.api.cloud.yandex.net/speech/v1/stt:recognize?lang=${lang}`,
        {
          method: "POST",
          headers: {
            Authorization: `Api-Key ${apiKey}`,
            "x-folder-id": folderId,
          },
          body: audioBuffer,
        }
      );

      const data = await response.json();
      const text = data.result?.alternatives?.[0]?.text || "";
      const confidence = data.result?.alternatives?.[0]?.confidence || 0;

      if (confidence > bestResult.confidence) {
        bestResult = { text, confidence, language: lang };
      }
    } catch (error) {
      continue;
    }
  }

  return { text: bestResult.text, language: bestResult.language };
}
```

### Streaming API –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ

```typescript
/**
 * –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Streaming API (–¥–ª—è –∞—É–¥–∏–æ > 30 —Å–µ–∫)
 */
export async function recognizeSpeechStreaming(
  request: YandexSTTRequest
): Promise<string> {
  const { apiKey, folderId, audioBuffer } = request;

  // –†–∞–∑–±–∏–≤–∞–µ–º –∞—É–¥–∏–æ –Ω–∞ —á–∞–Ω–∫–∏
  const chunkSize = 8000; // 8KB chunks
  const chunks: Buffer[] = [];

  for (let i = 0; i < audioBuffer.length; i += chunkSize) {
    chunks.push(audioBuffer.slice(i, i + chunkSize));
  }

  // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞–Ω–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
  let fullText = "";

  for (const chunk of chunks) {
    const response = await fetch(
      `https://stt.api.cloud.yandex.net/speech/v1/stt:recognize?folderId=${folderId}`,
      {
        method: "POST",
        headers: {
          Authorization: `Api-Key ${apiKey}`,
          "Transfer-Encoding": "chunked",
        },
        body: chunk,
      }
    );

    const data = await response.json();
    const text = data.result?.alternatives?.[0]?.text || "";
    fullText += " " + text;
  }

  return fullText.trim();
}
```

### –î–∏–∞–ª–æ–≥–æ–≤—ã–π —Ä–µ–∂–∏–º

```typescript
/**
 * –î–∏–∞–ª–æ–≥–æ–≤—ã–π handler —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
 */
interface VoiceContext {
  userId: number;
  step: "topic" | "industry" | "budget";
  data: {
    topic?: string;
    industry?: string;
    budget?: string;
  };
}

const conversations = new Map<number, VoiceContext>();

export async function voiceDialogHandler(ctx: BotContext): Promise<void> {
  if (!ctx.message || !("voice" in ctx.message)) return;

  const userId = ctx.from?.id;
  if (!userId) return;

  // –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
  let context = conversations.get(userId);
  if (!context) {
    context = {
      userId,
      step: "topic",
      data: {},
    };
    conversations.set(userId, context);
  }

  // –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ä–µ—á—å
  const voice = ctx.message.voice;
  const fileLink = await ctx.telegram.getFileLink(voice.file_id);
  const audioResponse = await fetch(fileLink.href);
  const audioBuffer = Buffer.from(await audioResponse.arrayBuffer());

  const recognizedText = await recognizeSpeech({
    apiKey: config.aiToken!,
    folderId: config.yandexFolderId!,
    audioBuffer,
  });

  // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —à–∞–≥–∞
  switch (context.step) {
    case "topic":
      context.data.topic = recognizedText;
      context.step = "industry";
      await ctx.reply(
        `üìù –¢–µ–º–∞: "${recognizedText}"\n\n` +
          `–¢–µ–ø–µ—Ä—å —Å–∫–∞–∂–∏—Ç–µ, –¥–ª—è –∫–∞–∫–æ–π –∏–Ω–¥—É—Å—Ç—Ä–∏–∏? üé§`
      );
      break;

    case "industry":
      context.data.industry = recognizedText;
      context.step = "budget";
      await ctx.reply(
        `üè¢ –ò–Ω–¥—É—Å—Ç—Ä–∏—è: "${recognizedText}"\n\n` + `–ö–∞–∫–æ–π –±—é–¥–∂–µ—Ç? üé§`
      );
      break;

    case "budget":
      context.data.budget = recognizedText;

      // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–¥–µ—é —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
      const prompt =
        `–¢–µ–º–∞: ${context.data.topic}\n` +
        `–ò–Ω–¥—É—Å—Ç—Ä–∏—è: ${context.data.industry}\n` +
        `–ë—é–¥–∂–µ—Ç: ${context.data.budget}`;

      const idea = await generateIdea(prompt);

      await ctx.reply(
        `üí∞ –ë—é–¥–∂–µ—Ç: "${recognizedText}"\n\n` +
          `üéØ –í–æ—Ç –≤–∞—à–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–¥–µ—è:\n\n${idea}`
      );

      // –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
      conversations.delete(userId);
      break;
  }
}
```

### –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π (–∫–æ–Ω—Ü–µ–ø—Ç)

```typescript
/**
 * –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞ –≥–æ–ª–æ—Å–∞ (–∫–æ–Ω—Ü–µ–ø—Ç)
 */
interface EmotionAnalysis {
  emotion: "positive" | "neutral" | "negative";
  confidence: number;
  energy: number;
}

async function analyzeVoiceEmotion(
  audioBuffer: Buffer
): Promise<EmotionAnalysis> {
  // –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ API:
  // - Yandex SpeechKit Emotion API
  // - Azure Speech Emotion Recognition
  // - Custom ML model

  // –ü—Ä–∏–º–µ—Ä (–ø—Å–µ–≤–¥–æ–∫–æ–¥):
  const response = await fetch("https://emotion-api.example.com/analyze", {
    method: "POST",
    body: audioBuffer,
  });

  const data = await response.json();

  return {
    emotion: data.emotion,
    confidence: data.confidence,
    energy: data.energy,
  };
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
export async function voiceHandlerWithEmotion(ctx: BotContext): Promise<void> {
  // ... –ø–æ–ª—É—á–∞–µ–º audioBuffer ...

  const emotion = await analyzeVoiceEmotion(audioBuffer);
  const text = await recognizeSpeech({ audioBuffer, ... });

  // –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –ø–æ–¥ —ç–º–æ—Ü–∏—é
  let ideaPrompt = text;
  if (emotion.emotion === "positive" && emotion.energy > 0.7) {
    ideaPrompt += " (make it exciting and ambitious)";
  } else if (emotion.emotion === "negative") {
    ideaPrompt += " (make it practical and reassuring)";
  }

  const idea = await generateIdea(ideaPrompt);
  await ctx.reply(idea);
}
```

## –£—Ç–∏–ª–∏—Ç—ã

### –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—É–¥–∏–æ

```typescript
/**
 * –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
 */
function validateVoiceMessage(voice: { duration: number; file_size: number }) {
  const errors: string[] = [];

  if (voice.duration > 30) {
    errors.push("–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–µ–≤—ã—à–∞–µ—Ç 30 —Å–µ–∫—É–Ω–¥");
  }

  if (voice.duration < 1) {
    errors.push("–°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ (–º–∏–Ω–∏–º—É–º 1 —Å–µ–∫—É–Ω–¥–∞)");
  }

  if (voice.file_size > 20 * 1024 * 1024) {
    errors.push("–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 20 –ú–ë");
  }

  return {
    valid: errors.length === 0,
    errors,
  };
}
```

### Retry –ª–æ–≥–∏–∫–∞

```typescript
/**
 * –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
 */
async function recognizeSpeechWithRetry(
  request: YandexSTTRequest,
  maxRetries = 3
): Promise<string> {
  let lastError: Error;

  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await recognizeSpeech(request);
    } catch (error) {
      lastError = error as Error;

      if (attempt < maxRetries) {
        // –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
        const delay = Math.pow(2, attempt) * 1000;
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
  }

  throw lastError!;
}
```

## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### Unit —Ç–µ—Å—Ç—ã

```typescript
// tests/services/yandex-stt.service.test.ts

import { describe, it, expect, vi } from "vitest";
import { recognizeSpeech } from "../../src/services/yandex-stt.service";

describe("YandexSTT Service", () => {
  it("should recognize speech successfully", async () => {
    // Mock fetch
    global.fetch = vi.fn().mockResolvedValue({
      ok: true,
      json: async () => ({
        result: {
          alternatives: [{ text: "—Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç", confidence: 0.95 }],
        },
      }),
    });

    const result = await recognizeSpeech({
      apiKey: "test-key",
      folderId: "test-folder",
      audioBuffer: Buffer.from("test"),
    });

    expect(result).toBe("—Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç");
  });

  it("should handle API errors", async () => {
    global.fetch = vi.fn().mockResolvedValue({
      ok: false,
      status: 401,
      text: async () => "Unauthorized",
    });

    await expect(
      recognizeSpeech({
        apiKey: "invalid-key",
        folderId: "test-folder",
        audioBuffer: Buffer.from("test"),
      })
    ).rejects.toThrow("Yandex STT API error: 401");
  });
});
```

---

**–≠—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø–æ–ª–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –≥–æ–ª–æ—Å–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è!**
